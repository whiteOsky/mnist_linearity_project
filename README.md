# ğŸ§  Exploring the Limits of Linearity on MNIST

> *A minimal yet expressive journey from pure linear models to deep nonlinearity â€” built from scratch with PyTorch.*

---

## ğŸŒŸ Overview

This project explores how different architectural and functional choices impact model performance on the **MNIST** handwritten digit dataset.

We begin from a simple **Linear Regression classifier** and gradually evolve it into a **nonlinear MLP** with ReLU, Dropout, and BatchNorm â€” quantifying *how much each step actually matters*.

<p align="center">
  <img src="assets/evolution_diagram.png" width="700">
</p>

---

## ğŸ§± Model Evolution Stages

| Stage | Architecture | Loss | Test Accuracy | Key Takeaways |
|:------|:-------------|:-----|:--------------|:---------------|
| â‘  Linear | 784 â†’ 10 | MSE | **92.6%** | Learns only linear boundaries |
| â‘¡ Linear + Softmax | 784 â†’ 10 | CrossEntropy | **92.1%** | Proper classification objective |
| â‘¢ MLP + ReLU | 784 â†’ 256 â†’ 10 | CrossEntropy | **97.5%** | Nonlinearity unlocks expressivity |
| â‘£ + Dropout | 784 â†’ 256 â†’ 10 | CrossEntropy | **97.3%** | Improves generalization |
| â‘¤ + BatchNorm | 784 â†’ BN â†’ 256 â†’ 10 | CrossEntropy | **97.7%** | Faster & more stable convergence |

---

## ğŸ§© Visual Results

| Model | Training Curve | Linear Weight Templates |
|:--:|:--:|:--:|
| **Linear (MSE)** | ![Linear MSE Curve](assets/linear_curve.png) | ![Weight Templates](assets/weights_linear.png) |
| **MLP + ReLU** | ![MLP Curve](assets/mlp_curve.png) | â€” |

---

## âš™ï¸ How to Reproduce

```bash
git clone https://github.com/whiteOsky/mnist_linearity_project.git
cd mnist_linearity_project
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Run each stage:
python -m src.train --model linear --loss mse --epochs 5
python -m src.train --model linear --loss crossentropy --epochs 5
python -m src.train --model mlp --hidden 256 --epochs 5
python -m src.train --model mlp --hidden 256 --dropout 0.5 --epochs 5
python -m src.train --model mlp --hidden 256 --batchnorm --epochs 5


å±•ç¤ºç½‘ç«™https://whiteosky.github.io/mnist-linearity-web/
